{"cells":[{"cell_type":"markdown","metadata":{"id":"l4qm44UA2o56"},"source":["<table align=\"left\">\n","  <td>\n","    <a href=\"https://colab.research.google.com/drive/1d8lmQCL40i0rGj_qMFjj5dUXdQYR_ixe\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"uvPodvPiSkyK"},"source":["---\n","\n","# **Licencia**\n","\n","**Autor**: Juan Francisco Puentes Calvo\n","\n","**Licencia**: GPL v3 (https://www.gnu.org/licenses/gpl-3.0.html)\n"]},{"cell_type":"markdown","metadata":{"id":"javkxsYWnya3"},"source":["# **Reconocimientos**\n","\n","* Ninguno, por ahora.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"lTXYMWalUXeC"},"source":["## Reconocimiento de gestos en las manos\n","\n","**Esta celda se ejecuta en un Jupyter local, para tener acceso a la webcam.**"]},{"cell_type":"code","source":["!pip -q install ipywidgets jupyter-ui-poll mediapipe"],"metadata":{"id":"mVOpqkokVs2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: Crea un interfaz que abra la cámara con varios botones. Habrá en total 3 botones, etiquetados como piedra, papel y tijera. Al pulsar cualquiera de estos botones se almacenará una imagen de nombre \"<etiqueta><número>.png\", en el subdirectorio \"manos\", donde <etiqueta> es la etiqueta del botón y <número> es un contador. La webcam permanecerá abierta hasta que se pulse \"q\".\n","\n","import cv2\n","import ipywidgets as widgets\n","from IPython.display import display\n","import os\n","from jupyter_ui_poll import ui_events;\n","\n","# Crea el directorio \"manos\" si no existe\n","if not os.path.exists(\"manos\"):\n","    os.makedirs(\"manos\")\n","\n","# Contadores para cada gesto\n","contador_piedra = 0\n","contador_papel = 0\n","contador_tijera = 0\n","\n","# Función para capturar y guardar una imagen\n","def capturar_imagen(etiqueta):\n","    global cap, contador_piedra, contador_papel, contador_tijera\n","\n","    # Incrementa el contador correspondiente\n","    if etiqueta == \"piedra\":\n","        contador_piedra += 1\n","        nombre_archivo = f\"manos/piedra{contador_piedra}.png\"\n","    elif etiqueta == \"papel\":\n","        contador_papel += 1\n","        nombre_archivo = f\"manos/papel{contador_papel}.png\"\n","    elif etiqueta == \"tijera\":\n","        contador_tijera += 1\n","        nombre_archivo = f\"manos/tijera{contador_tijera}.png\"\n","\n","    # Captura la imagen\n","    ret, frame = cap.read()\n","    if ret:\n","        cv2.imwrite(nombre_archivo, frame)\n","        print(f\"Imagen guardada como {nombre_archivo}\")\n","\n","# Crea los botones\n","boton_piedra = widgets.Button(description=\"Piedra\")\n","boton_papel = widgets.Button(description=\"Papel\")\n","boton_tijera = widgets.Button(description=\"Tijera\")\n","\n","# Define las funciones para manejar los eventos de los botones\n","def on_click_piedra(b):\n","    capturar_imagen(\"piedra\")\n","def on_click_papel(b):\n","    capturar_imagen(\"papel\")\n","def on_click_tijera(b):\n","    capturar_imagen(\"tijera\")\n","\n","# Asigna las funciones a los eventos de los botones\n","boton_piedra.on_click(on_click_piedra)\n","boton_papel.on_click(on_click_papel)\n","boton_tijera.on_click(on_click_tijera)\n","\n","# Muestra los botones\n","display(boton_piedra, boton_papel, boton_tijera)\n","\n","# Abre la cámara\n","cap = cv2.VideoCapture(0)\n","\n","if not cap.isOpened():\n","    print(\"No se pudo abrir la cámara\")\n","    cap.release()\n","else:\n","    print(\"Cámara abierta correctamente\")\n","\n","    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n","    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n","\n","    # Bucle principal\n","    while True:\n","        ret, frame = cap.read()\n","        if ret:\n","            cv2.imshow(\"Webcam\", frame)\n","            with ui_events() as poll: poll(10)\n","        else:\n","            break\n","        # Espera la tecla 'q' para salir\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    # Libera los recursos\n","    cap.release()\n","    cv2.destroyAllWindows()\n"],"metadata":{"id":"wSIhYLGaRVv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: En el subdirectoprio \"manos\" hay imágenes, cada una de una mano. Busca la imagen llamada \"papel105.png\", aplicale una identificación de gesto usando mediapipe y muestra la imagen con los puntos de referencia.\n","\n","import mediapipe as mp\n","import cv2\n","\n","mp_hands = mp.solutions.hands\n","mp_drawing = mp.solutions.drawing_utils\n","\n","# Carga la imagen\n","imagen_path = \"manos/papel105.png\"\n","imagen = cv2.imread(imagen_path)\n","\n","# Inicializa el modelo de detección de manos\n","with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n","    # Procesa la imagen\n","    resultados = hands.process(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n","\n","    # Dibuja los puntos de referencia si se detectaron manos\n","    if resultados.multi_hand_landmarks:\n","        for hand_landmarks in resultados.multi_hand_landmarks:\n","            mp_drawing.draw_landmarks(imagen, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n","\n","# Muestra la imagen con los puntos de referencia\n","cv2.imshow(\"Imagen con puntos de referencia\", imagen)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFdWzYwE2UQW","executionInfo":{"status":"ok","timestamp":1723470639129,"user_tz":-120,"elapsed":38669,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}},"outputId":"c7915a2c-6d23-4350-c205-e2528c5800e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["I0000 00:00:1723470600.467029    5710 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723470600.544901   30058 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 4070/PCIe/SSE2\n","W0000 00:00:1723470600.549030   30045 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723470600.556457   30044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]}]},{"cell_type":"markdown","source":["Los nombres de los ficheros de cada imagen es del tipo \"<label><number>.png\". Por ejemplo \"papel43.png\".\n","\n","Para extraer la etiqueta hay que eliminar la extensión y el número.\n","\n","---\n","\n","Para cada punto de referencia hay que calcular la distancia euclídea de este a otro, en este caso a la muñeca.\n","Así pues el vector de características es la distancia de cada punto de referencia a la muñeca."],"metadata":{"id":"EWcJfkq3knCA"}},{"cell_type":"code","source":["# prompt: En el subdirectoprio \"manos\" hay imágenes, cada una de una mano. Para cada una de ellas haz una identificación del gesto usando mediapipe, obten los puntos de referencia de la mano, calcula su distancia respecto al punto que representa la muñeca. Almacena cada uno de estos vectores en un Dataframe. La última columna de cada fila es la etiqueta. No muestres nada.\n","\n","import pandas as pd\n","\n","# Inicializa el modelo de detección de manos\n","with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n","    # Lista para almacenar los vectores de características y etiquetas\n","    datos = []\n","\n","    # Recorre las imágenes en el directorio \"manos\"\n","    for filename in os.listdir(\"manos\"):\n","        if filename.endswith(\".png\"):\n","            # Extrae la etiqueta del nombre del archivo\n","            etiqueta = filename.split('.')[0][:-1]\n","            etiqueta = etiqueta.rstrip('0123456789')\n","\n","            # Carga la imagen\n","            imagen_path = os.path.join(\"manos\", filename)\n","            imagen = cv2.imread(imagen_path)\n","\n","            # Procesa la imagen\n","            resultados = hands.process(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n","\n","            # Obtiene los puntos de referencia si se detectaron manos\n","            if resultados.multi_hand_landmarks:\n","                for hand_landmarks in resultados.multi_hand_landmarks:\n","                    # Calcula la distancia de cada punto de referencia a la muñeca\n","                    vector_caracteristicas = []\n","                    muñeca = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n","                    for punto in hand_landmarks.landmark:\n","                        distancia = ((punto.x - muñeca.x)**2 + (punto.y - muñeca.y)**2 + (punto.z - muñeca.z)**2)**0.5\n","                        vector_caracteristicas.append(distancia)\n","\n","                    # Agrega el vector de características y la etiqueta a la lista de datos\n","                    vector_caracteristicas.append(etiqueta)\n","                    datos.append(vector_caracteristicas)\n","\n","# Crea un DataFrame a partir de los datos\n","columnas = [f\"Punto_{i}\" for i in range(len(datos[0]) - 1)] + [\"Etiqueta\"]\n","df = pd.DataFrame(datos, columns=columnas)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzZjS1zf7VJy","executionInfo":{"status":"ok","timestamp":1723471979356,"user_tz":-120,"elapsed":11793,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}},"outputId":"7df14a06-6bb1-4c30-bc56-7757a5690b38"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["I0000 00:00:1723471967.530564    5710 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723471967.560790   33693 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 4070/PCIe/SSE2\n","W0000 00:00:1723471967.565258   33680 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723471967.571738   33678 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","/home/fran/CODE/iTI2025/.iti2025/lib/python3.12/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n","  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"]}]},{"cell_type":"code","source":["# prompt: Guarda el dataframe 'df' en un fichero llamado 'manos.csv'.\n","\n","df.to_csv('manos.csv', index=False)\n"],"metadata":{"id":"_dV2-Sf1z0i3","executionInfo":{"status":"ok","timestamp":1723471984455,"user_tz":-120,"elapsed":7,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["### Dado un dataframe con vectres de características anotados, hacer un clustering"],"metadata":{"id":"VmYw3Opx3Qeg"}},{"cell_type":"code","source":["# prompt: Dado un fichero csv referenciado mediante una url, descárgalo, ábreo y muestra info sobre su contenido.\n","\n","import pandas as pd\n","\n","# URL del fichero CSV\n","url = 'https://raw.github.com/FranPuentes/iTI2025/main/data/manos.csv'\n","\n","# Descarga el fichero CSV\n","df = pd.read_csv(url)\n","\n","# Muestra información sobre el contenido del DataFrame\n","print(df.info())\n"],"metadata":{"id":"ljDZoqYa3Zm0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723471469352,"user_tz":-120,"elapsed":1383,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}},"outputId":"7b0a8f44-10c0-4c11-dee9-c4ac268d87d9"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 422 entries, 0 to 421\n","Data columns (total 21 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   Landmark_0   422 non-null    object\n"," 1   Landmark_1   422 non-null    object\n"," 2   Landmark_2   422 non-null    object\n"," 3   Landmark_3   422 non-null    object\n"," 4   Landmark_4   422 non-null    object\n"," 5   Landmark_5   422 non-null    object\n"," 6   Landmark_6   422 non-null    object\n"," 7   Landmark_7   422 non-null    object\n"," 8   Landmark_8   422 non-null    object\n"," 9   Landmark_9   422 non-null    object\n"," 10  Landmark_10  422 non-null    object\n"," 11  Landmark_11  422 non-null    object\n"," 12  Landmark_12  422 non-null    object\n"," 13  Landmark_13  422 non-null    object\n"," 14  Landmark_14  422 non-null    object\n"," 15  Landmark_15  422 non-null    object\n"," 16  Landmark_16  422 non-null    object\n"," 17  Landmark_17  422 non-null    object\n"," 18  Landmark_18  422 non-null    object\n"," 19  Landmark_19  422 non-null    object\n"," 20  Label        422 non-null    object\n","dtypes: object(21)\n","memory usage: 69.4+ KB\n","None\n"]}]},{"cell_type":"code","source":["# prompt: Usando este dataframe entrena un modelo de clustering para 3 clusters, y usando TSNE muestra en 2d su dispersión. Ten en cuenta que la última columna es una etiqueta, no la uses pra clusterizar, pero si para poner un color en cada fila.\n","\n","from sklearn.cluster import KMeans\n","from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","\n","# Separa las características de las etiquetas\n","X = df.drop('Label', axis=1)\n","y = df['Label']\n","\n","# Crea y entrena el modelo KMeans\n","kmeans = KMeans(n_clusters=3)\n","kmeans.fit(X)\n","\n","# Aplica TSNE para reducir la dimensionalidad a 2D\n","tsne = TSNE(n_components=2)\n","X_tsne = tsne.fit_transform(X)\n","\n","# Grafica los clusters\n","plt.figure(figsize=(8, 6))\n","for label in y.unique():\n","    plt.scatter(X_tsne[y == label, 0], X_tsne[y == label, 1], label=label)\n","plt.legend()\n","plt.title('Clusters de Gestos de Mano')\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"hbuCZmuw6Gdx","executionInfo":{"status":"error","timestamp":1723471680212,"user_tz":-120,"elapsed":491,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}},"outputId":"1816082a-8aa6-476b-c5ca-0989cf593a56"},"execution_count":26,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"could not convert string to float: '[0.08459293842315674, 0.07278060913085938, 0.003569992718496451]'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_5710/1806406029.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Crea y entrena el modelo KMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Aplica TSNE para reducir la dimensionalidad a 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CODE/iTI2025/.iti2025/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/CODE/iTI2025/.iti2025/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \"\"\"\n\u001b[0;32m-> 1464\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m   1465\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CODE/iTI2025/.iti2025/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CODE/iTI2025/.iti2025/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CODE/iTI2025/.iti2025/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CODE/iTI2025/.iti2025/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0.08459293842315674, 0.07278060913085938, 0.003569992718496451]'"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2aEv1b1HbxbRFcf54aHMB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}