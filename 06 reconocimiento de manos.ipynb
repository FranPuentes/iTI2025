{"cells":[{"cell_type":"markdown","metadata":{"id":"l4qm44UA2o56"},"source":["<table align=\"left\">\n","  <td>\n","    <a href=\"https://colab.research.google.com/drive/1d8lmQCL40i0rGj_qMFjj5dUXdQYR_ixe\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"uvPodvPiSkyK"},"source":["---\n","\n","# **Licencia**\n","\n","**Autor**: Juan Francisco Puentes Calvo\n","\n","**Licencia**: GPL v3 (https://www.gnu.org/licenses/gpl-3.0.html)\n"]},{"cell_type":"markdown","metadata":{"id":"javkxsYWnya3"},"source":["# **Reconocimientos**\n","\n","* Ninguno, por ahora.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"lTXYMWalUXeC"},"source":["## Reconocimiento de gestos en las manos\n","\n","**Esta celda se ejecuta en un Jupyter local, para tener acceso a la webcam.**"]},{"cell_type":"code","source":["!pip -q install ipywidgets jupyter-ui-poll mediapipe"],"metadata":{"id":"mVOpqkokVs2r","executionInfo":{"status":"ok","timestamp":1723465805345,"user_tz":-120,"elapsed":14469,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# prompt: Crea un interfaz que abra la cámara con varios botones. Habrá en total 3 botones, etiquetados como piedra, papel y tijera. Al pulsar cualquiera de estos botones se almacenará una imagen de nombre \"<etiqueta><número>.png\", en el subdirectorio \"manos\", donde <etiqueta> es la etiqueta del botón y <número> es un contador. La webcam permanecerá abierta hasta que se pulse \"q\".\n","\n","import cv2\n","import ipywidgets as widgets\n","from IPython.display import display\n","import os\n","from jupyter_ui_poll import ui_events;\n","\n","# Crea el directorio \"manos\" si no existe\n","if not os.path.exists(\"manos\"):\n","    os.makedirs(\"manos\")\n","\n","# Contadores para cada gesto\n","contador_piedra = 0\n","contador_papel = 0\n","contador_tijera = 0\n","\n","# Función para capturar y guardar una imagen\n","def capturar_imagen(etiqueta):\n","    global cap, contador_piedra, contador_papel, contador_tijera\n","\n","    # Incrementa el contador correspondiente\n","    if etiqueta == \"piedra\":\n","        contador_piedra += 1\n","        nombre_archivo = f\"manos/piedra{contador_piedra}.png\"\n","    elif etiqueta == \"papel\":\n","        contador_papel += 1\n","        nombre_archivo = f\"manos/papel{contador_papel}.png\"\n","    elif etiqueta == \"tijera\":\n","        contador_tijera += 1\n","        nombre_archivo = f\"manos/tijera{contador_tijera}.png\"\n","\n","    # Captura la imagen\n","    ret, frame = cap.read()\n","    if ret:\n","        cv2.imwrite(nombre_archivo, frame)\n","        print(f\"Imagen guardada como {nombre_archivo}\")\n","\n","# Crea los botones\n","boton_piedra = widgets.Button(description=\"Piedra\")\n","boton_papel = widgets.Button(description=\"Papel\")\n","boton_tijera = widgets.Button(description=\"Tijera\")\n","\n","# Define las funciones para manejar los eventos de los botones\n","def on_click_piedra(b):\n","    capturar_imagen(\"piedra\")\n","def on_click_papel(b):\n","    capturar_imagen(\"papel\")\n","def on_click_tijera(b):\n","    capturar_imagen(\"tijera\")\n","\n","# Asigna las funciones a los eventos de los botones\n","boton_piedra.on_click(on_click_piedra)\n","boton_papel.on_click(on_click_papel)\n","boton_tijera.on_click(on_click_tijera)\n","\n","# Muestra los botones\n","display(boton_piedra, boton_papel, boton_tijera)\n","\n","# Abre la cámara\n","cap = cv2.VideoCapture(0)\n","\n","if not cap.isOpened():\n","    print(\"No se pudo abrir la cámara\")\n","    cap.release()\n","else:\n","    print(\"Cámara abierta correctamente\")\n","\n","    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n","    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n","\n","    # Bucle principal\n","    while True:\n","        ret, frame = cap.read()\n","        if ret:\n","            cv2.imshow(\"Webcam\", frame)\n","            with ui_events() as poll: poll(10)\n","        else:\n","            break\n","        # Espera la tecla 'q' para salir\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    # Libera los recursos\n","    cap.release()\n","    cv2.destroyAllWindows()\n"],"metadata":{"id":"wSIhYLGaRVv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: En el subdirectoprio \"manos\" hay imágenes, cada una de una mano. Busca la imagen llamada \"papel105.png\", aplicale una identificación de gesto usando mediapipe y muestra la imagen con los puntos de referencia.\n","\n","import mediapipe as mp\n","import cv2\n","\n","mp_hands = mp.solutions.hands\n","mp_drawing = mp.solutions.drawing_utils\n","\n","# Carga la imagen\n","imagen_path = \"manos/papel105.png\"\n","imagen = cv2.imread(imagen_path)\n","\n","# Inicializa el modelo de detección de manos\n","with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n","    # Procesa la imagen\n","    resultados = hands.process(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n","\n","    # Dibuja los puntos de referencia si se detectaron manos\n","    if resultados.multi_hand_landmarks:\n","        for hand_landmarks in resultados.multi_hand_landmarks:\n","            mp_drawing.draw_landmarks(imagen, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n","\n","# Muestra la imagen con los puntos de referencia\n","cv2.imshow(\"Imagen con puntos de referencia\", imagen)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFdWzYwE2UQW","executionInfo":{"status":"ok","timestamp":1723470639129,"user_tz":-120,"elapsed":38669,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}},"outputId":"c7915a2c-6d23-4350-c205-e2528c5800e3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["I0000 00:00:1723470600.467029    5710 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723470600.544901   30058 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 4070/PCIe/SSE2\n","W0000 00:00:1723470600.549030   30045 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723470600.556457   30044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]}]},{"cell_type":"markdown","source":["Los nombres de los ficheros de cada imagen es del tipo \"<label><number>.png\". Por ejemplo \"papel43.png\".\n","\n","Para extraer la etiqueta hay que eliminar la extensión y el número."],"metadata":{"id":"EWcJfkq3knCA"}},{"cell_type":"code","source":["# prompt: En el subdirectoprio \"manos\" hay imágenes, cada una de una mano. Para cada una de ellas haz una identificación del gesto usando mediapipe, obten los puntos de referencia de la mano, normalízalo respecto al punto que representa la muñeca. Almacena cada uno de estos vectores en un Dataframe. La última columna de cada fila es la etiqueta. No muestres nada.\n","\n","import mediapipe as mp\n","import pandas as pd\n","\n","mp_hands = mp.solutions.hands\n","mp_drawing = mp.solutions.drawing_utils\n","\n","# Inicializa el DataFrame\n","df = pd.DataFrame()\n","\n","# Itera sobre los archivos en el directorio \"manos\"\n","for filename in os.listdir(\"manos\"):\n","    if filename.endswith(\".png\"):\n","        # Carga la imagen\n","        image_path = os.path.join(\"manos\", filename)\n","        image = cv2.imread(image_path)\n","\n","        # Procesa la imagen con MediaPipe\n","        with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n","            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","\n","            if results.multi_hand_landmarks:\n","                for hand_landmarks in results.multi_hand_landmarks:\n","                    # Extrae los puntos de referencia de la mano\n","                    landmarks = []\n","                    for landmark in hand_landmarks.landmark:\n","                        landmarks.append([landmark.x, landmark.y, landmark.z])\n","\n","                    # Normaliza los puntos de referencia respecto a la muñeca (punto 0)\n","                    wrist = landmarks[0]\n","                    normalized_landmarks = [[x - wrist[0], y - wrist[1], z - wrist[2]] for x, y, z in landmarks]\n","\n","                    # Extrae la etiqueta del nombre del archivo\n","                    label = filename.split('.')[0][:-1]\n","                    label = label.rstrip('0123456789')\n","\n","                    # Agrega los puntos de referencia normalizados y la etiqueta al DataFrame\n","                    row = normalized_landmarks[1:]  # Excluye la muñeca\n","                    row.append(label)\n","                    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n","\n","# Nombra las columnas del DataFrame\n","num_landmarks = len(df.columns) - 1\n","column_names = [f\"Landmark_{i}\" for i in range(num_landmarks)]\n","column_names.append(\"Label\")\n","df.columns = column_names\n"],"metadata":{"id":"EamPxxnnjUcD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: Guarda el dataframe 'df' en un fichero llamado 'manos.csv'.\n","\n","df.to_csv('manos.csv', index=False)\n"],"metadata":{"id":"_dV2-Sf1z0i3","executionInfo":{"status":"ok","timestamp":1723470203640,"user_tz":-120,"elapsed":52,"user":{"displayName":"Juan Francisco Puentes Calvo","userId":"04307711343502565257"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["### Dado un dataframe con vectres de características anotados, hacer un clustering"],"metadata":{"id":"VmYw3Opx3Qeg"}},{"cell_type":"code","source":[],"metadata":{"id":"ljDZoqYa3Zm0"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUgeG13d/QB8g1p7k3lgeM"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}